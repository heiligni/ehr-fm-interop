{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics on the unprocessed MIMIC Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from file_paths import MIMIC_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TABLE_DIR = \"/home/niclas/Dokumente/thesis/results/tables\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_table(table, filename):\n",
    "    df_pd = table.to_pandas()\n",
    "    latex_table = tabulate(df_pd, headers='keys', tablefmt='latex')\n",
    "\n",
    "    with open(os.path.join(TABLE_DIR, filename), \"w\") as f:\n",
    "        f.write(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze Admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import os\n",
    "\n",
    "# Load your data\n",
    "df = pl.read_csv(os.path.join(MIMIC_DIR, \"hosp/admissions.csv\"))\n",
    "\n",
    "# Define a complete mapping to normalize race categories\n",
    "race_mapping = {\n",
    "    \"HISPANIC/LATINO - MEXICAN\": \"HISPANIC/LATINO\",\n",
    "    \"HISPANIC/LATINO - CENTRAL AMERICAN\": \"HISPANIC/LATINO\",\n",
    "    \"AMERICAN INDIAN/ALASKA NATIVE\": \"OTHER\",\n",
    "    \"SOUTH AMERICAN\": \"HISPANIC/LATINO\",\n",
    "    \"HISPANIC/LATINO - CUBAN\": \"HISPANIC/LATINO\",\n",
    "    \"WHITE - RUSSIAN\": \"WHITE\",\n",
    "    \"WHITE - EASTERN EUROPEAN\": \"WHITE\",\n",
    "    \"PORTUGUESE\": \"OTHER\",  # Often categorized under White due to European origin\n",
    "    \"PATIENT DECLINED TO ANSWER\": \"UNKNOWN\",\n",
    "    \"WHITE - BRAZILIAN\": \"WHITE\",  # Often categorized under White or Hispanic depending on context\n",
    "    \"HISPANIC/LATINO - PUERTO RICAN\": \"HISPANIC/LATINO\",\n",
    "    \"HISPANIC/LATINO - GUATEMALAN\": \"HISPANIC/LATINO\",\n",
    "    \"WHITE\": \"WHITE\",\n",
    "    \"HISPANIC/LATINO - SALVADORAN\": \"HISPANIC/LATINO\",\n",
    "    \"UNKNOWN\": \"UNKNOWN\",\n",
    "    \"HISPANIC/LATINO - COLUMBIAN\": \"HISPANIC/LATINO\",\n",
    "    \"ASIAN - CHINESE\": \"ASIAN\",\n",
    "    \"BLACK/AFRICAN\": \"BLACK\",\n",
    "    \"WHITE - OTHER EUROPEAN\": \"WHITE\",\n",
    "    \"ASIAN - KOREAN\": \"ASIAN\",\n",
    "    \"HISPANIC OR LATINO\": \"HISPANIC/LATINO\",\n",
    "    \"BLACK/CAPE VERDEAN\": \"BLACK\",\n",
    "    \"HISPANIC/LATINO - DOMINICAN\": \"HISPANIC/LATINO\",\n",
    "    \"NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER\": \"OTHER\",\n",
    "    \"ASIAN\": \"ASIAN\",\n",
    "    \"HISPANIC/LATINO - HONDURAN\": \"HISPANIC/LATINO\",\n",
    "    \"ASIAN - ASIAN INDIAN\": \"ASIAN\",\n",
    "    \"BLACK/CARIBBEAN ISLAND\": \"BLACK\",\n",
    "    \"UNABLE TO OBTAIN\": \"UNKNOWN\",\n",
    "    \"BLACK/AFRICAN AMERICAN\": \"BLACK\",\n",
    "    \"OTHER\": \"OTHER\",\n",
    "    \"ASIAN - SOUTH EAST ASIAN\": \"ASIAN\",\n",
    "    \"MULTIPLE RACE/ETHNICITY\": \"OTHER\",\n",
    "}\n",
    "\n",
    "# Normalize race column using mapping\n",
    "df = df.with_columns(\n",
    "    pl.col(\"race\").map_dict(race_mapping).alias(\"normalized_race\")\n",
    ")\n",
    "\n",
    "# Step 1: Remove 'OTHER' and 'UNKNOWN' where possible\n",
    "df_filtered = df.filter(~pl.col(\"normalized_race\").is_in([\"OTHER\", \"UNKNOWN\"]))\n",
    "\n",
    "# Step 2: Check for remaining subject_ids without valid race after filtering\n",
    "missing_race_ids = df.join(df_filtered, on=\"subject_id\", how=\"anti\")['subject_id'].unique()\n",
    "\n",
    "# Step 3: Combine the filtered DataFrame with original for missing subject_ids\n",
    "df_combined = pl.concat([\n",
    "    df_filtered,\n",
    "    df.filter(pl.col(\"subject_id\").is_in(missing_race_ids))\n",
    "])\n",
    "\n",
    "# Step 4: Resolve conflicts by taking the first available race\n",
    "df_aggregated = df_combined.groupby(\"subject_id\").agg(\n",
    "    pl.col(\"normalized_race\").first().alias(\"final_race\")\n",
    ")\n",
    "\n",
    "race_counts = df_aggregated.groupby(\"final_race\").count().rename({'count': 'race_count'})\n",
    "\n",
    "# Step 6: Calculate percentages\n",
    "total_patients = df_aggregated.height\n",
    "race_counts = race_counts.with_columns(\n",
    "    (pl.col(\"race_count\") / total_patients * 100).alias(\"percentage\")\n",
    ")\n",
    "\n",
    "# Convert to a DataFrame for easier viewing (if needed)\n",
    "race_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import os\n",
    "\n",
    "# Load your data\n",
    "df = pl.read_csv(os.path.join(MIMIC_DIR, \"hosp/admissions.csv\"))\n",
    "\n",
    "# Define a complete mapping to normalize race categories\n",
    "race_mapping = {\n",
    "    \"HISPANIC/LATINO - MEXICAN\": \"HISPANIC/LATINO\",\n",
    "    \"HISPANIC/LATINO - CENTRAL AMERICAN\": \"HISPANIC/LATINO\",\n",
    "    \"AMERICAN INDIAN/ALASKA NATIVE\": \"OTHER\",\n",
    "    \"SOUTH AMERICAN\": \"HISPANIC/LATINO\",\n",
    "    \"HISPANIC/LATINO - CUBAN\": \"HISPANIC/LATINO\",\n",
    "    \"WHITE - RUSSIAN\": \"WHITE\",\n",
    "    \"WHITE - EASTERN EUROPEAN\": \"WHITE\",\n",
    "    \"PORTUGUESE\": \"OTHER\",  # Often categorized under White due to European origin\n",
    "    \"PATIENT DECLINED TO ANSWER\": \"UNKNOWN\",\n",
    "    \"WHITE - BRAZILIAN\": \"WHITE\",  # Often categorized under White or Hispanic depending on context\n",
    "    \"HISPANIC/LATINO - PUERTO RICAN\": \"HISPANIC/LATINO\",\n",
    "    \"HISPANIC/LATINO - GUATEMALAN\": \"HISPANIC/LATINO\",\n",
    "    \"WHITE\": \"WHITE\",\n",
    "    \"HISPANIC/LATINO - SALVADORAN\": \"HISPANIC/LATINO\",\n",
    "    \"UNKNOWN\": \"UNKNOWN\",\n",
    "    \"HISPANIC/LATINO - COLUMBIAN\": \"HISPANIC/LATINO\",\n",
    "    \"ASIAN - CHINESE\": \"ASIAN\",\n",
    "    \"BLACK/AFRICAN\": \"BLACK\",\n",
    "    \"WHITE - OTHER EUROPEAN\": \"WHITE\",\n",
    "    \"ASIAN - KOREAN\": \"ASIAN\",\n",
    "    \"HISPANIC OR LATINO\": \"HISPANIC/LATINO\",\n",
    "    \"BLACK/CAPE VERDEAN\": \"BLACK\",\n",
    "    \"HISPANIC/LATINO - DOMINICAN\": \"HISPANIC/LATINO\",\n",
    "    \"NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER\": \"OTHER\",\n",
    "    \"ASIAN\": \"ASIAN\",\n",
    "    \"HISPANIC/LATINO - HONDURAN\": \"HISPANIC/LATINO\",\n",
    "    \"ASIAN - ASIAN INDIAN\": \"ASIAN\",\n",
    "    \"BLACK/CARIBBEAN ISLAND\": \"BLACK\",\n",
    "    \"UNABLE TO OBTAIN\": \"UNKNOWN\",\n",
    "    \"BLACK/AFRICAN AMERICAN\": \"BLACK\",\n",
    "    \"OTHER\": \"OTHER\",\n",
    "    \"ASIAN - SOUTH EAST ASIAN\": \"ASIAN\",\n",
    "    \"MULTIPLE RACE/ETHNICITY\": \"OTHER\",\n",
    "}\n",
    "\n",
    "# Normalize race column using mapping\n",
    "df = df.with_columns(\n",
    "    pl.col(\"race\").map_dict(race_mapping).alias(\"normalized_race\")\n",
    ")\n",
    "\n",
    "# Define the priority for races (higher number means higher priority)\n",
    "priority = {\n",
    "    \"UNKNOWN\": 0,\n",
    "    \"OTHER\": 1,\n",
    "    \"HISPANIC/LATINO\": 2,\n",
    "    \"ASIAN\": 3,\n",
    "    \"BLACK\": 4,\n",
    "    \"WHITE\": 5\n",
    "}\n",
    "\n",
    "# Add priority column to help with the selection process\n",
    "df = df.with_columns(\n",
    "    pl.col(\"normalized_race\").map_dict(priority).alias(\"priority\")\n",
    ")\n",
    "\n",
    "# Group by subject_id and resolve conflicts by selecting race with highest priority\n",
    "# In case of tie, we pick one race at random\n",
    "df_unique_race = df.groupby(\"subject_id\").agg([\n",
    "    pl.col(\"normalized_race\").sort_by(\"priority\", descending=True).first(),\n",
    "])\n",
    "\n",
    "# Provide an overview of the normalized race distribution\n",
    "race_distribution = df_unique_race.groupby(\"normalized_race\").agg([\n",
    "    pl.count().alias(\"count\")\n",
    "])\n",
    "\n",
    "race_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"subject_id\"].unique().len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv(os.path.join(MIMIC_DIR, \"hosp/admissions.csv\"))\n",
    "# Calculate mortality per admission\n",
    "df = df.with_columns(\n",
    "    pl.col(\"hospital_expire_flag\").cast(pl.Boolean)\n",
    ")\n",
    "\n",
    "# Mortality per admission\n",
    "mortality_per_admission = df.groupby(\"hospital_expire_flag\").agg([\n",
    "    pl.count().alias(\"count\")\n",
    "])\n",
    "\n",
    "print(mortality_per_admission)\n",
    "\n",
    "# Mortality per patient\n",
    "# Group by subject_id and check if the patient has died in any admission\n",
    "mortality_per_patient = df.groupby(\"subject_id\").agg([\n",
    "    (pl.col(\"hospital_expire_flag\").max()).alias(\"died\")\n",
    "])\n",
    "\n",
    "# Calculate mortality statistics per patient\n",
    "mortality_per_patient_stats = mortality_per_patient.groupby(\"died\").agg([\n",
    "    pl.count().alias(\"count\")\n",
    "])\n",
    "mortality_per_patient_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the admissions data\n",
    "df = pl.read_csv(os.path.join(MIMIC_DIR, 'hosp/admissions.csv'))\n",
    "\n",
    "# Convert the 'admittime' and 'dischtime' columns to datetime\n",
    "df = df.with_columns([\n",
    "    pl.col('admittime').str.strptime(pl.Datetime, '%Y-%m-%d %H:%M:%S').alias('admittime_dt'),\n",
    "    pl.col('dischtime').str.strptime(pl.Datetime, '%Y-%m-%d %H:%M:%S').alias('dischtime_dt')\n",
    "])\n",
    "\n",
    "# Create the 'overnight' column\n",
    "df = df.with_columns([\n",
    "    (pl.col('dischtime_dt') > (pl.col('admittime_dt') + pl.duration(days=1))).alias('overnight')\n",
    "])\n",
    "\n",
    "# Group by 'admission_type' and aggregate the 'overnight' column\n",
    "agg_df = df.groupby('admission_type').agg([\n",
    "    pl.count('overnight').alias('total_admissions'),\n",
    "    pl.sum('overnight').alias('overnight_admissions'),\n",
    "    (pl.sum('overnight') / pl.count('overnight')).alias('overnight_ratio')\n",
    "])\n",
    "\n",
    "agg_df_pd = agg_df.to_pandas()\n",
    "latex_table = tabulate(agg_df_pd, headers='keys', tablefmt='latex')\n",
    "print(latex_table)\n",
    "\n",
    "with open(os.path.join(TABLE_DIR, \"overnight_admissions_by_adm_type.tex\"), \"w\") as f:\n",
    "    f.write(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnoses_df = pl.read_csv(os.path.join(MIMIC_DIR, 'hosp/diagnoses_icd.csv'))\n",
    "icd_diagnoses_df = pl.read_csv(os.path.join(MIMIC_DIR, 'hosp/d_icd_diagnoses.csv'), schema_overrides={'icd_code': pl.Utf8})\n",
    "\n",
    "\n",
    "# Filter the data to include only main diagnoses (seq_num == 1)\n",
    "main_diagnoses_df = diagnoses_df.filter(pl.col('seq_num') == 1)\n",
    "\n",
    "joined_df = main_diagnoses_df.join(icd_diagnoses_df, on=['icd_code', 'icd_version'], how='left')\n",
    "\n",
    "\n",
    "# Count the occurrences of each icd_code for main diagnoses\n",
    "main_diagnoses_count = joined_df.groupby(['icd_version', 'icd_code', 'long_title']).agg([\n",
    "    pl.count('icd_code').alias('count')\n",
    "])\n",
    "\n",
    "# Sort the diagnoses by count in descending order\n",
    "main_diagnoses_count = main_diagnoses_count.sort('count', descending=True)\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "top_20_diagnoses = main_diagnoses_count[0:20]\n",
    "\n",
    "save_table(top_20_diagnoses, \"top_20_main_diagnoses.tex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnoses_df = pl.read_csv(os.path.join(MIMIC_DIR, 'hosp/diagnoses_icd.csv'))\n",
    "icd_diagnoses_df = pl.read_csv(os.path.join(MIMIC_DIR, 'hosp/d_icd_diagnoses.csv'), schema_overrides={'icd_code': pl.Utf8})\n",
    "\n",
    "\n",
    "joined_df = diagnoses_df.join(icd_diagnoses_df, on=['icd_code', 'icd_version'], how='left')\n",
    "\n",
    "\n",
    "# Count the occurrences of each icd_code for main diagnoses\n",
    "diagnoses_count = joined_df.groupby(['icd_version', 'icd_code', 'long_title']).agg([\n",
    "    pl.count('icd_code').alias('count')\n",
    "])\n",
    "\n",
    "# Sort the diagnoses by count in descending order\n",
    "diagnoses_count = diagnoses_count.sort('count', descending=True)\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "top_20_diagnoses = diagnoses_count[0:20]\n",
    "print(top_20_diagnoses)\n",
    "\n",
    "save_table(top_20_diagnoses, \"top_20_diagnoses.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of diagnoses per patient\n",
    "diagnoses_per_patient = diagnoses_df.groupby('subject_id').agg([\n",
    "    pl.count('icd_code').alias('num_diagnoses')\n",
    "])\n",
    "\n",
    "diagnoses_stats = diagnoses_per_patient[\"num_diagnoses\"].describe()\n",
    "\n",
    "# Print statistics\n",
    "print(diagnoses_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnoses_per_patient_pd = diagnoses_per_patient.to_pandas()\n",
    "\n",
    "# Plot histogram of the number of diagnoses per patient\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(diagnoses_per_patient_pd['num_diagnoses'], bins=30, edgecolor='black', alpha=0.7)\n",
    "plt.title('Distribution of Diagnoses per Patient')\n",
    "plt.xlabel('Number of Diagnoses')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot boxplot of the number of diagnoses per patient\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(diagnoses_per_patient_pd['num_diagnoses'], vert=False)\n",
    "plt.title('Boxplot of Diagnoses per Patient')\n",
    "plt.xlabel('Number of Diagnoses')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot cumulative distribution function (CDF)\n",
    "sorted_diagnoses = np.sort(diagnoses_per_patient_pd['num_diagnoses'])\n",
    "yvals = np.arange(1, len(sorted_diagnoses)+1) / float(len(sorted_diagnoses))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(sorted_diagnoses, yvals)\n",
    "plt.title('Cumulative Distribution Function of Diagnoses per Patient')\n",
    "plt.xlabel('Number of Diagnoses')\n",
    "plt.ylabel('CDF')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the procedures data\n",
    "procedures_df = pl.read_csv(os.path.join(MIMIC_DIR, 'hosp/procedures_icd.csv'))\n",
    "\n",
    "# Load the d_icd_procedures data with icd_code as string\n",
    "icd_procedures_df = pl.read_csv(os.path.join(MIMIC_DIR, 'hosp/d_icd_procedures.csv'), schema_overrides={'icd_code': pl.Utf8})\n",
    "\n",
    "# Join the procedures data with the d_icd_procedures data on icd_code and icd_version\n",
    "joined_procedures_df = procedures_df.join(icd_procedures_df, on=['icd_code', 'icd_version'], how='left')\n",
    "\n",
    "# Calculate the number of procedures per patient\n",
    "procedures_per_patient = joined_procedures_df.groupby('subject_id').agg([\n",
    "    pl.count('icd_code').alias('num_procedures')\n",
    "])\n",
    "\n",
    "# Compute statistics\n",
    "procedures_stats = procedures_per_patient[\"num_procedures\"].describe()\n",
    "\n",
    "# Print statistics\n",
    "print(procedures_stats)\n",
    "save_table(procedures_stats, \"procedure_stats.tex\")\n",
    "\n",
    "# Identify and display the top ten most common procedures\n",
    "top_procedures = joined_procedures_df.groupby(['icd_code', 'long_title']).agg([\n",
    "    pl.count('icd_code').alias('count')\n",
    "]).sort('count', descending=True).limit(10)\n",
    "\n",
    "print(top_procedures)\n",
    "save_table(top_procedures, \"top_10_procedures.tex\")\n",
    "\n",
    "# Convert to Pandas DataFrame for compatibility with plotting libraries\n",
    "procedures_per_patient_pd = procedures_per_patient.to_pandas()\n",
    "\n",
    "# Plot histogram of the number of procedures per patient\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(procedures_per_patient_pd['num_procedures'], bins=30, edgecolor='black', alpha=0.7)\n",
    "plt.title('Distribution of Procedures per Patient')\n",
    "plt.xlabel('Number of Procedures')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot boxplot of the number of procedures per patient\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(procedures_per_patient_pd['num_procedures'], vert=False)\n",
    "plt.title('Boxplot of Procedures per Patient')\n",
    "plt.xlabel('Number of Procedures')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot cumulative distribution function (CDF)\n",
    "sorted_procedures = np.sort(procedures_per_patient_pd['num_procedures'])\n",
    "yvals = np.arange(1, len(sorted_procedures)+1) / float(len(sorted_procedures))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(sorted_procedures, yvals)\n",
    "plt.title('Cumulative Distribution Function of Procedures per Patient')\n",
    "plt.xlabel('Number of Procedures')\n",
    "plt.ylabel('CDF')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify schema overrides for columns that should be treated as strings\n",
    "schema_overrides = {\n",
    "    'gsn': pl.Utf8,\n",
    "    'ndc': pl.Utf8\n",
    "}\n",
    "\n",
    "# Load the prescriptions data\n",
    "prescriptions_df = pl.read_csv(os.path.join(MIMIC_DIR, 'hosp/prescriptions.csv'), schema_overrides=schema_overrides)\n",
    "\n",
    "\n",
    "# Calculate the number of prescriptions per patient\n",
    "prescriptions_per_patient = prescriptions_df.groupby('subject_id').agg([\n",
    "    pl.count('drug').alias('num_prescriptions')\n",
    "])\n",
    "\n",
    "# Compute statistics\n",
    "prescriptions_stats = prescriptions_per_patient[\"num_prescriptions\"].describe()\n",
    "\n",
    "# Print statistics\n",
    "print(prescriptions_stats)\n",
    "save_table(prescriptions_stats, \"prescription_stats.tex\")\n",
    "\n",
    "# Identify and display the top ten most common prescriptions\n",
    "top_prescriptions = prescriptions_df.groupby('drug').agg([\n",
    "    pl.count('drug').alias('count')\n",
    "]).sort('count', descending=True).limit(10)\n",
    "\n",
    "print(top_prescriptions)\n",
    "save_table(top_prescriptions, \"top_10_prescriptions.tex\")\n",
    "\n",
    "# Convert to Pandas DataFrame for compatibility with plotting libraries\n",
    "prescriptions_per_patient_pd = prescriptions_per_patient.to_pandas()\n",
    "\n",
    "# Plot histogram of the number of prescriptions per patient\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(prescriptions_per_patient_pd['num_prescriptions'], bins=30, edgecolor='black', alpha=0.7)\n",
    "plt.title('Distribution of Prescriptions per Patient')\n",
    "plt.xlabel('Number of Prescriptions')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot boxplot of the number of prescriptions per patient\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(prescriptions_per_patient_pd['num_prescriptions'], vert=False)\n",
    "plt.title('Boxplot of Prescriptions per Patient')\n",
    "plt.xlabel('Number of Prescriptions')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot cumulative distribution function (CDF)\n",
    "sorted_prescriptions = np.sort(prescriptions_per_patient_pd['num_prescriptions'])\n",
    "yvals = np.arange(1, len(sorted_prescriptions)+1) / float(len(sorted_prescriptions))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(sorted_prescriptions, yvals)\n",
    "plt.title('Cumulative Distribution Function of Prescriptions per Patient')\n",
    "plt.xlabel('Number of Prescriptions')\n",
    "plt.ylabel('CDF')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions_df = pl.read_csv(os.path.join(MIMIC_DIR, 'hosp/admissions.csv'))\n",
    "\n",
    "\n",
    "# Calculate length of stay\n",
    "admissions_df = admissions_df.with_columns([\n",
    "    (pl.col('dischtime').str.strptime(pl.Datetime, '%Y-%m-%d %H:%M:%S') - pl.col('admittime').str.strptime(pl.Datetime, '%Y-%m-%d %H:%M:%S')).alias('length_of_stay')\n",
    "])\n",
    "\n",
    "# Convert length of stay to days\n",
    "admissions_df = admissions_df.with_columns([\n",
    "    (pl.col('length_of_stay').cast(pl.Duration('ns')).dt.hours() / 24).alias('length_of_stay_days')\n",
    "])\n",
    "\n",
    "# Compute statistics\n",
    "los_stats = admissions_df['length_of_stay_days'].describe()\n",
    "\n",
    "# Print statistics\n",
    "print(los_stats)\n",
    "\n",
    "# Percentage of stays longer than 7 days\n",
    "long_stays_percentage = (admissions_df.filter(pl.col('length_of_stay_days') > 7).height / admissions_df.height) * 100\n",
    "print(f'Percentage of stays longer than 7 days: {long_stays_percentage:.2f}%')\n",
    "\n",
    "# Convert to Pandas DataFrame for compatibility with plotting libraries\n",
    "admissions_df_pd = admissions_df.to_pandas()\n",
    "\n",
    "# Plot histogram of length of stay\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(admissions_df_pd['length_of_stay_days'], bins=30, edgecolor='black', alpha=0.7)\n",
    "plt.title('Distribution of Length of Stay')\n",
    "plt.xlabel('Length of Stay (days)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot boxplot of length of stay\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(admissions_df_pd['length_of_stay_days'], vert=False)\n",
    "plt.title('Boxplot of Length of Stay')\n",
    "plt.xlabel('Length of Stay (days)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mortality_by_diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate overall mortality rate\n",
    "overall_mortality_rate = (admissions_df['hospital_expire_flag'].sum() / admissions_df.height) * 100\n",
    "print(f'Overall mortality rate: {overall_mortality_rate:.2f}%')\n",
    "\n",
    "# Join with diagnoses data to analyze mortality by specific diagnoses\n",
    "main_diagnoses_df = diagnoses_df.filter(pl.col('seq_num') == 1)\n",
    "\n",
    "# Join admissions with main diagnoses\n",
    "admissions_with_diagnoses = admissions_df.join(main_diagnoses_df, on='hadm_id', how='left')\n",
    "\n",
    "# Calculate mortality rate by diagnosis\n",
    "mortality_by_diagnosis = admissions_with_diagnoses.groupby(['icd_code', 'icd_version']).agg([\n",
    "    pl.count('icd_code').alias('total_admissions'),\n",
    "    pl.sum('hospital_expire_flag').alias('total_deaths')\n",
    "])\n",
    "\n",
    "mortality_by_diagnosis = mortality_by_diagnosis.with_columns([\n",
    "    (pl.col('total_deaths') / pl.col('total_admissions') * 100).alias('mortality_rate')\n",
    "])\n",
    "\n",
    "# Join with ICD descriptions\n",
    "mortality_by_diagnosis = mortality_by_diagnosis.join(icd_diagnoses_df, on=['icd_code', 'icd_version'], how='left')\n",
    "\n",
    "# Print top diagnoses by mortality rate\n",
    "top_mortality_diagnoses = mortality_by_diagnosis.sort('mortality_rate', descending=True).limit(10)\n",
    "print(top_mortality_diagnoses)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
